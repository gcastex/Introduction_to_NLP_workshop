{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a hole in the ground there lived a hobbit.', 'Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a hole in the ground there lived a hobbit.\n",
      "Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat\n",
      ": it was a hobbit-hole, and that means comfort.\n",
      "[In a hole in the ground there lived a hobbit., Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat, : it was a hobbit-hole, and that means comfort.]\n"
     ]
    }
   ],
   "source": [
    "# Spacy\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(text)\n",
    "for s in doc.sents:\n",
    "    print(s)\n",
    "sentences = [s for s in doc.sents]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In a hole in the ground there lived a hobbit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'a', 'hole', 'in', 'the', 'ground', 'there', 'lived', 'a', 'hobbit', '.', 'Not', 'a', 'nasty', ',', 'dirty', ',', 'wet', 'hole', ',', 'filled', 'with', 'the', 'ends', 'of', 'worms', 'and', 'an', 'oozy', 'smell', ',', 'nor', 'yet', 'a', 'dry', ',', 'bare', ',', 'sandy', 'hole', 'with', 'nothing', 'in', 'it', 'to', 'sit', 'down', 'on', 'or', 'to', 'eat', ':', 'it', 'was', 'a', 'hobbit-hole', ',', 'and', 'that', 'means', 'comfort', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('a', 'DT'), ('hole', 'NN'), ('in', 'IN'), ('the', 'DT'), ('ground', 'NN'), ('there', 'RB'), ('lived', 'VBD'), ('a', 'DT'), ('hobbit', 'NN'), ('.', '.'), ('Not', 'RB'), ('a', 'DT'), ('nasty', 'JJ'), (',', ','), ('dirty', 'JJ'), (',', ','), ('wet', 'JJ'), ('hole', 'NN'), (',', ','), ('filled', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('ends', 'NNS'), ('of', 'IN'), ('worms', 'NNS'), ('and', 'CC'), ('an', 'DT'), ('oozy', 'NN'), ('smell', 'NN'), (',', ','), ('nor', 'CC'), ('yet', 'RB'), ('a', 'DT'), ('dry', 'NN'), (',', ','), ('bare', 'NN'), (',', ','), ('sandy', 'JJ'), ('hole', 'NN'), ('with', 'IN'), ('nothing', 'NN'), ('in', 'IN'), ('it', 'PRP'), ('to', 'TO'), ('sit', 'VB'), ('down', 'RP'), ('on', 'IN'), ('or', 'CC'), ('to', 'TO'), ('eat', 'VB'), (':', ':'), ('it', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('hobbit-hole', 'JJ'), (',', ','), ('and', 'CC'), ('that', 'DT'), ('means', 'VBZ'), ('comfort', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# With Part of Speech\n",
    "tagged = nltk.pos_tag(word_tokens)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ADP\n",
      "a DET\n",
      "hole NOUN\n",
      "in ADP\n",
      "the DET\n",
      "ground NOUN\n",
      "there ADV\n",
      "lived VERB\n",
      "a DET\n",
      "hobbit NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Spacy\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(text)\n",
    "\n",
    "for word in doc:\n",
    "    print(word.text,  word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"We don't want any adventures here, thank you!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "do\n",
      "n't\n",
      "want\n",
      "ani\n",
      "adventur\n",
      "here\n",
      ",\n",
      "thank\n",
      "you\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "for word in tokenized:\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no stemming in Spacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Elvish singing is not a thing to miss\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This This\n",
      "is be\n",
      "the the\n",
      "story story\n",
      "of of\n",
      "how how\n",
      "a a\n",
      "Baggins Baggins\n",
      "had have\n",
      "an an\n",
      "adventure adventure\n",
      ", ,\n",
      "and and\n",
      "found find\n",
      "himself himself\n",
      "doing do\n",
      "and and\n",
      "saying say\n",
      "things things\n",
      "altogether altogether\n",
      "unexpected unexpected\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnetLem = WordNetLemmatizer()\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "for word in tokenized:\n",
    "    print(word, wordnetLem.lemmatize(word, pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elvish elvish\n",
      "singing singing\n",
      "is be\n",
      "not not\n",
      "a a\n",
      "thing thing\n",
      "to to\n",
      "miss miss\n"
     ]
    }
   ],
   "source": [
    "# Spacy\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(text)\n",
    "\n",
    "for word in doc:\n",
    "    print(word.text,  word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this be the story of how a Baggins have an adventure , and find -PRON- do and say thing altogether unexpected . \n"
     ]
    }
   ],
   "source": [
    "text = \"This is the story of how a Baggins had an adventure, and found himself doing and saying things altogether unexpected.\"\n",
    "doc = nlp(text)\n",
    "s=\"\"\n",
    "for word in doc:\n",
    "    s+=word.lemma_+\" \"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This be the story of how a Baggins have an adventure , and find himself do and say things altogether unexpected . \n"
     ]
    }
   ],
   "source": [
    "text = \"This is the story of how a Baggins had an adventure, and found himself doing and saying things altogether unexpected.\"\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "s=\"\"\n",
    "for word in tokenized:\n",
    "    s+=wordnetLem.lemmatize(word, pos=\"v\")+\" \"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words and Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/guillaumec/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In a hole in the ground there lived a hobbit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hole', 'ground', 'lived', 'hobbit']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english')) \n",
    "\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "filtered = [w.lower() for w in tokenized if (not w.lower() in stop and w.isalnum())]\n",
    "print(filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hole', 'ground', 'lived', 'hobbit']\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "doc = nlp(text)\n",
    "token_list = [token.text for token in doc if token.is_punct == False]\n",
    "\n",
    "filtered = [word for word in token_list if nlp.vocab[word].is_stop == False]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'a', 'hole', 'in', 'the', 'ground', 'there', 'lived', 'a', 'hobbit', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"In a hole in the ground there lived a hobbit.\"\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "f =  [w.lower() for w in tokenized]\n",
    "print(f)\n",
    "filtered = [w.lower() for w in tokenized \\\n",
    "            if (not w.lower in stop and w.isalnum())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In True\n",
      "a True\n",
      "hole False\n",
      "in True\n",
      "the True\n",
      "ground False\n",
      "there True\n",
      "lived False\n",
      "a True\n",
      "hobbit False\n",
      ". False\n"
     ]
    }
   ],
   "source": [
    "for w in tokenized:\n",
    "    print(w, w.lower() in stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kettle', 'wish', 'behind', 'sing', 'home', 'ahead', 'jump', 'begin', 'world', 'find', 'put']\n"
     ]
    }
   ],
   "source": [
    "t1 = \"I wish I was at home [...] with the kettle just beginning to sing!\"\n",
    "t2 = \"Home is now behind you, the world is ahead!\"\n",
    "t3 = \"He jumped up to [...] put his kettle on — and found he was not home at all.\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "stop = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "tokenized = nltk.word_tokenize(t1)\n",
    "f =  [w.lower() for w in tokenized]\n",
    "filtered1 = [lem.lemmatize(w.lower(), pos=\"v\") for w in tokenized \\\n",
    "            if (not w.lower() in stop and w.isalnum())]\n",
    "\n",
    "\n",
    "tokenized = nltk.word_tokenize(t2)\n",
    "f =  [w.lower() for w in tokenized]\n",
    "filtered2 = [lem.lemmatize(w.lower(), pos=\"v\") for w in tokenized \\\n",
    "            if (not w.lower() in stop and w.isalnum())]\n",
    "\n",
    "\n",
    "tokenized = nltk.word_tokenize(t3)\n",
    "f =  [w.lower() for w in tokenized]\n",
    "filtered3 = [lem.lemmatize(w.lower(), pos=\"v\") for w in tokenized \\\n",
    "            if (not w.lower() in stop and w.isalnum())]\n",
    "\n",
    "\n",
    "# tokenized = nltk.word_tokenize(t4)\n",
    "# f =  [w.lower() for w in tokenized]\n",
    "# filtered4 = [lem.lemmatize(w.lower(), pos=\"v\") for w in tokenized \\\n",
    "#             if (not w.lower() in stop and w.isalnum())]\n",
    "\n",
    "vocab = list(set(filtered1+filtered2+filtered3))\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "v1 = []\n",
    "for w in vocab:\n",
    "    c = 1 if w in filtered1 else 0\n",
    "    v1.append(c)\n",
    "print(v1)\n",
    "\n",
    "v2 = []\n",
    "for w in vocab:\n",
    "    c = 1 if w in filtered2 else 0\n",
    "    v2.append(c)\n",
    "print(v2)\n",
    "\n",
    "v3 = []\n",
    "for w in vocab:\n",
    "    c = 1 if w in filtered3 else 0\n",
    "    v3.append(c)\n",
    "print(v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-88c96933d5e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sent' is not defined"
     ]
    }
   ],
   "source": [
    "sent = nltk.word_tokenize(sent)\n",
    "sent = nltk.pos_tag(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Not that Belladonna Took ever had any adventures after she became Mrs. Bungo Baggins. Bungo, that was Bilbo’s father, built the most luxurious hobbit-hole for her (and partly with her money) that was to be found either under The Hill or over The Hill or across The Water, and there they remained to the end of their days.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Not that \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Belladonna Took\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " ever had any adventures after she became Mrs. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bungo Baggins\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bungo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", that was \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bilbo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "’s father, built the most luxurious hobbit-hole for her (and partly with her money) that was to be found either under The Hill or over \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Hill\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " or across \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Water\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       ", and there they remained to \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the end of their days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "displacy.render(doc, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
